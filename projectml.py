# -*- coding: utf-8 -*-
"""ProjectML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ENsI2ViHEdN1CuLboGe8ynZQZ5P3euFA
"""

import numpy as np
import matplotlib.pyplot as plt
import random
import os
import PIL

from keras.utils import np_utils                          # tools for creating one-hot encoding
from keras.models import Sequential                       # Type of model we wish to use
from keras.layers.core import Dense, Dropout, Activation  # Types of layers we wish to use

from skimage.transform import resize                      # Used to scale/resize image arrays

from sklearn.metrics import confusion_matrix              # Used to quickly make confusion matrix

from google.colab import drive          #gettting access of google drive where the data folder is stored
drive.mount('/content/drive')

!cp -r "/content/drive/MyDrive/Food_Dataset/Food_Dataset" "/content/"             #copying the datset from the drive to colab environment

!ls /content/Food_Dataset

# Location of dataset
DATASET_PATH = "/content/Food_Dataset"
# Desired resolution of images
TARGET_WIDTH = 128
TARGET_HEIGHT = 128

# Invert image because dark backgrounds can improve accuracy
INVERT = False

# Keeping aside 20% for validation and 20% for test
VAL_RATIO = 0.2
TEST_RATIO = 0.2

random.seed(17)

# Loading images as Numpy arrays

# We want to record the labels and assign a ground truth label as a number to each sample
labels = []
y_all = []    # 'y' - 1D vector of the ground labels
X_all = []    # 'X' - 3D array of all image samples 

# Finding the directories in the dataset folder 
for label in os.listdir(DATASET_PATH):
  class_dir = os.path.join(DATASET_PATH, label)
  if os.path.isdir(class_dir) and label != ".ipynb_checkpoints":

    # Adding the name of the folder to our labels list
    labels.append(label)

    # Going through each image in the folder
    for i, file in enumerate(os.listdir(class_dir)):
      if file != ".ipynb_checkpoints":

        # Opening image and converting to RGB
        file_path = os.path.join(class_dir, file)
        img = PIL.Image.open(file_path).convert('RGB')

        # Convert the image to a Numpy array, optionally invert, and append to X
        img_array = np.asarray(img)
        if INVERT:
          img_array = 255 - img_array
        X_all.append(img_array)

        # Add label to the y array
        y_all.append(label)

    # Show how many images we loaded
    print("Added", str(i + 1), "images from", label)

# Calculate total number of samples
num_samples = len(X_all)

# Sort the labels list by alphabetical order
labels = sorted(labels)

# Print out labels and number of samples
print(labels)
print("Number of samples:", num_samples)

### Converting labels to numbers

# Show the labels before the conversion
print("Before:", y_all)

# Convert each label to its index in the labels
y_out = []
for i, label in enumerate(y_all):
  y_out.append(labels.index(label))
y_all = y_out

# Show the labels after the conversion
print("After:", y_all)

### Shuffle samples and labels together, divide into test, validation, and training sets

# Shuffle samples and associated labels together
X_y = list(zip(X_all, y_all))
random.shuffle(X_y)
X_all, y_all = zip(*X_y)

# Calculate number of validation and test samples to put aside (round down)
num_samples_test = int(TEST_RATIO * num_samples)
num_samples_val = int(VAL_RATIO * num_samples)

# The first `num_samples_test` samples of the shuffled list becomes the test set
X_test = X_all[:num_samples_test]
y_test = y_all[:num_samples_test]

# The next `num_samples_val` samples of the shuffled list becomes the validation set
X_val = X_all[num_samples_test:(num_samples_test + num_samples_val)]
y_val = y_all[num_samples_test:(num_samples_test + num_samples_val)]

# The remaining samples become the training set
X_train = X_all[(num_samples_test + num_samples_val):]
y_train = y_all[(num_samples_test + num_samples_val):]

# Remember the number of samples in the test set
num_samples_train = len(X_train)

# Print out the number of test, validation, and training samples
print("Number of test samples:", num_samples_test)
print("Number of validation samples:", num_samples_val)
print("Number of training samples:", num_samples_train)

X = np.array(X_train)
X.shape

### View one of the training samples

# Chose which sample you want to view
idx = 10

# Print out label (numbe and string) and part of the array
print("Label: " + str(y_train[idx]) + " (" + labels[y_train[idx]] + ")")
print(X_train[idx])

# Display image from array
plt.imshow(X_train[idx], cmap='gray', vmin=0, vmax=255)

### Function to resize list of images
def resize_images(images, width, height, anti_aliasing=True):
  """
  Prove a list of Numpy arrays (in images parameter) to have them all resized to desired height and
  width. Returns the list of newly resized image arrays.

  NOTE: skimage resize returns *normalized* image arrays (values between 0..1)
  """
  X_out = []
  for i, img in enumerate(images):
    X_out.append(resize(img, (height, width), anti_aliasing=anti_aliasing))
  return X_out

### Scale/crop images

# Resize (scale) all images in the training set
X_train = resize_images(X_train, TARGET_WIDTH, TARGET_HEIGHT)

# Resize (scale) all images in the validation set
X_val = resize_images(X_val, TARGET_WIDTH, TARGET_HEIGHT)

# Resize (scale) all images in the test set
X_test = resize_images(X_test, TARGET_WIDTH, TARGET_HEIGHT)

### View training sample again (after they all have been scaled)

# Chose which sample you want to view
idx = 0

# Print out label (numbe and string) and part of the array
print("Label: " + str(y_train[idx]) + " (" + labels[y_train[idx]] + ")")
print("First row:", X_train[idx][:1,:])

# Display image from array (note that images have been normalized)
plt.imshow(X_train[idx], cmap='gray', vmin=0, vmax=1)

### Convert list of samples and labels into Numpy arrays

# Training set
X_train = np.asarray(X_train)
y_train = np.asarray(y_train)

# Validation set
X_val = np.asarray(X_val)
y_val = np.asarray(y_val)

# Test set
X_test = np.asarray(X_test)
y_test = np.asarray(y_test)

# Print out the new Numpy array shapes (always a good idea to check the shapes!)
print("Training X:", X_train.shape)
print("Training y:", y_train.shape)
print("Validation X:", X_val.shape)
print("Validation y:", y_val.shape)
print("Test X:", X_test.shape)
print("Test y:", y_test.shape)

# Convert labels (integers) to one-hot encoding

# Get number of classes
num_classes = len(labels)

# Use Keras's np_utils to create one-hot encoding (note the capital 'Y' - 2D array)
Y_train = np_utils.to_categorical(y_train, num_classes)
Y_val = np_utils.to_categorical(y_val, num_classes)
Y_test = np_utils.to_categorical(y_test, num_classes)

# Print out shapes (capital 'Y' is our one-hot matrix!)
print("Y train:", Y_train.shape)
print("Y val:", Y_val.shape)
print("Y test:", Y_test.shape)

# Print out a few examples from training set
for i in range(10):
  print("Label: " + str(y_train[i]) + " | One-hot:", Y_train[i])

X_train.shape

import tensorflow as tf
from tensorflow import keras
from keras.layers import Conv2D

"""Model with only CNN"""

# from keras.models import Sequential
# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# # Define the input shape of the images
# input_shape = (TARGET_WIDTH, TARGET_HEIGHT,3)

# # Create a sequential model
# model = Sequential()

# # Add a convolutional layer with 32 filters, a 3x3 kernel size, and relu activation
# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))

# # Add a max pooling layer with a pool size of 2x2
# model.add(MaxPooling2D(pool_size=(2, 2)))

# # Add a second convolutional layer with 64 filters and relu activation
# model.add(Conv2D(64, (3, 3), activation='relu'))

# # Add a second max pooling layer with a pool size of 2x2
# model.add(MaxPooling2D(pool_size=(2, 2)))

# # Flatten the output of the convolutional layers
# model.add(Flatten())

# # Add a fully-connected layer with 64 units and relu activation
# model.add(Dense(128, activation='relu'))

# # Add dropout to prevent overfitting
# model.add(Dropout(0.5))

# # Add the output layer with softmax activation for classification
# model.add(Dense(num_classes, activation='softmax'))

# # Compile the model with categorical cross-entropy loss and Adam optimizer
# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# # Print the model summary
# model.summary()

"""Model with transfer learning added with CNN

"""

from keras.applications import VGG16
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D

input_shape = (TARGET_WIDTH, TARGET_HEIGHT, 3)

# Loading the pre-trained VGG16 model
vgg = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)

# Freezing the layers in the pre-trained model
for layer in vgg.layers:
    layer.trainable = False

# Creating a sequential model
model = Sequential()

# Adding the pre-trained VGG16 model to the sequential model
model.add(vgg)

# Adding a CNN layer with 32 filters, a kernel size of 3x3, and ReLU activation
model.add(Conv2D(64, (3, 3), activation='relu'))

# Adding a max pooling layer with a pool size of 2x2
model.add(MaxPooling2D(pool_size=(2, 2)))

# Flattening the output of the CNN layer
model.add(Flatten())

# Adding a fully-connected layer with 64 units and relu activation
model.add(Dense(128, activation='relu'))

# Adding dropout to prevent overfitting
model.add(Dropout(0.5))

# Adding the output layer with softmax activation for classification
model.add(Dense(num_classes, activation='softmax'))

# Compiling the model with categorical cross-entropy loss and Adam optimizer
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Printing the model summary
model.summary()

# Training the model
history = model.fit(X_train, 
                    Y_train, 
                    batch_size=30, 
                    epochs=25, 
                    verbose=1,
                    validation_data=(X_val, Y_val))

X_train.shape

Y_train.shape

# Plot training and validation accuracy and loss over time

# Extract accuracy and loss values (in list form) from the history
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Create a list of epoch numbers
epochs = range(1, len(acc) + 1)

# Plot training and validation loss values over time
plt.figure()
plt.plot(epochs, loss, color='green', marker='.', label='Training loss')
plt.plot(epochs, val_loss, color='red', marker='.', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

# Plot training and validation accuracies over time
plt.figure()
plt.plot(epochs, acc, color='green', marker='.', label='Training acc')
plt.plot(epochs, val_acc, color='red', marker='.', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()

# Try predicting label with validation sample 

# Change this to try a different sample from the test set
idx = 0
x = np.expand_dims(X_val[idx], 0)
# Make prediction using trained model
y_pred = model.predict(x)

# Find index of highest score in output
predicted_label = np.argmax(y_pred)
actual_label = np.argmax(Y_val[idx])

# Display model output, predicted label, actual label
print("Model output:", y_pred)
print("Predicted label:", predicted_label, "-", labels[predicted_label])
print("Actual label:", actual_label, "-", labels[actual_label])

# Creating confusion matrix from validation set

# Find predictions from all validation samples
Y_pred = model.predict(X_val)
print("Validation output shape:", Y_pred.shape)

# Convert actual and predicted validation one-hot encoding to numerical labels
y_val = np.argmax(Y_val, axis=1)
y_pred = np.argmax(Y_pred, axis=1)

# Print some values from actual and predicted validation sets (first 50 samples)
print("Actual validation labels:\t", y_val[:50])
print("Predicted validation labels:\t", y_pred[:50])

# Computing confusion matrix (note: we need to transpose SKLearn matrix to make it match Edge Impulse)
cm = confusion_matrix(y_val, y_pred)
cm = np.transpose(cm)

# Printing confusion matrix
print()
print(" ---> Predicted labels")
print("|")
print("v Actual labels")
print("\t\t\t" + ' '.join("{!s:6}".format('(' + str(i) + ')') for i in range(num_classes)))
for row in range(num_classes):
  print("{:>12} ({}):  [{}]".format(labels[row], row, ' '.join("{:6}".format(i) for i in cm[row])))

# Evaluating model on validation set
score = model.evaluate(X_val, Y_val)
print("Validation loss:", score[0])
print("Validation accuracy:", score[1])

# Evaluating model on entire test set
score = model.evaluate(X_test, Y_test)
print("Test loss:", score[0])
print("Test accuracy:", score[1])

"""# Reference

1. The refrence for creating CNN model was taken from  -   https://github.com/karneamol/CourseraEdgeImpulseComputerVision/blob/main/1.2.3%20-%20Training%20an%20Image%20Classifier%20with%20Keras/image_classifier_dnn.ipynb
2.  The reference for adding Vgg 16 to gthe model was taken from - https://builtin.com/machine-learning/vgg16

3. Refrence for one hot encoding was taken from -https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html

4. How to connect drive with google colab was understood from Chat gpt

5. Data set was taken from - https://www.kaggle.com/datasets/anshulmehtakaggl/themassiveindianfooddataset

6. Idea on how to use Keras was taken from - https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/
"""